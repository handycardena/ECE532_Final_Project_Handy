{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01  0.    0.02 -0.   -0.    0.    0.04 -0.09  0.01  0.01 -0.01  0.\n",
      " -0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from spicy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A = np.genfromtxt('Data_Raw.csv', delimiter=',')\n",
    "#print(A.dtype)\n",
    "\n",
    "Data = np.genfromtxt('Data.csv', delimiter=',')\n",
    "x_train = Data[0:1001,0:14] # features\n",
    "y_train = Data[0:1001,14] # corresponding labels\n",
    "\n",
    "# evaluation data\n",
    "x_eval= Data[1001:12330,0:14] # features\n",
    "y_eval = Data[1001:12330,14] # corresponding labels\n",
    "\n",
    "# X = Data[0:3,0:14]\n",
    "# y = Data[:,14] \n",
    "\n",
    "# Classifier 1\n",
    "#w = (X^T X)^(-1)X^T y\n",
    "X = x_train\n",
    "y = y_train\n",
    "w = np.linalg.inv(X.transpose()@X)@X.transpose()@y\n",
    "#A = np.linalg.inv(X@X.T)\n",
    "\n",
    "print(np.round(w,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from spicy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#A = np.genfromtxt('Data_Raw.csv', delimiter=',')\n",
    "#print(A.dtype)\n",
    "\n",
    "Data = np.genfromtxt('Data.csv', delimiter=',')\n",
    "x_train = Data[0:1001,0:14] # features\n",
    "y_train = Data[0:1001,14] # corresponding labels\n",
    "\n",
    "# evaluation data\n",
    "x_eval= Data[1001:12330,0:14] # features\n",
    "y_eval = Data[1001:12330,14] # corresponding labels\n",
    "\n",
    "# X = Data[0:3,0:14]\n",
    "# y = Data[:,14] \n",
    "\n",
    "# Classifier 1\n",
    "#w = (X^T X)^(-1)X^T y\n",
    "X = x_eval\n",
    "y = y_eval\n",
    "w = np.linalg.inv(X.transpose()@X)@X.transpose()@y\n",
    "#A = np.linalg.inv(X@X.T)\n",
    "\n",
    "print(np.round(w,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d\n",
    "\n",
    "x_eval = X\n",
    "y_eval = y\n",
    "\n",
    "# all features\n",
    "print('considering all features')\n",
    "x_train = X\n",
    "w_train = w\n",
    "y_hat = np.sign(x_train@w_train)\n",
    "\n",
    "error_vec = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_eval))]\n",
    "print('Errors: '+ str(sum(error_vec)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec)/len(error_vec))+'%')\n",
    "\n",
    "# 3 main features\n",
    "print('considering 3 main features')\n",
    "x_train = X[:, [0, 2, 3]] \n",
    "w_train = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y\n",
    "y_hat = np.sign(x_train@w_train)\n",
    "\n",
    "error_vec = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_eval))]\n",
    "print('Errors: '+ str(sum(error_vec)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec)/len(error_vec))+'%')\n",
    "\n",
    "# w = (X^T X)^(-1)X^T y\n",
    "# w_opt = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y_train\n",
    "# print(w_opt)\n",
    "# y_hat = np.sign(x_eval@w_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2f\n",
    "in_data = loadmat('face_emotion_data.mat')\n",
    "\n",
    "X = in_data['X']\n",
    "y = in_data['y']\n",
    "\n",
    "x_1 = X[range(0,16), :]\n",
    "x_2 = X[range(16,32), :]\n",
    "x_3 = X[range(16,48), :]\n",
    "x_4 = X[range(48,64), :]\n",
    "x_5 = X[range(64,80), :]\n",
    "x_6 = X[range(80,96), :]\n",
    "x_7 = X[range(96,112), :]\n",
    "x_8 = X[range(112,128), :]\n",
    "\n",
    "y_1 = y[range(0,16), :]\n",
    "y_2 = y[range(16,32), :]\n",
    "y_3 = y[range(16,48), :]\n",
    "y_4 = y[range(48,64), :]\n",
    "y_5 = y[range(64,80), :]\n",
    "y_6 = y[range(80,96), :]\n",
    "y_7 = y[range(96,112), :]\n",
    "y_8 = y[range(112,128), :]\n",
    "\n",
    "# 1 variation, hold x_8 and y_8\n",
    "print('considering 1st variation')\n",
    "x_train = np.vstack((x_1, x_2, x_3, x_4, x_5, x_6, x_7)) \n",
    "y_train = np.vstack((y_1, y_2, y_3, y_4, y_5, y_6, y_7)) \n",
    "w_train = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y_train\n",
    "y_hat = np.sign(x_8@w_train)\n",
    "# print(w_train)\n",
    "error_vec_1 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_8))]\n",
    "print('Errors: '+ str(sum(error_vec_1)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec_1)/16)+'%')\n",
    "\n",
    "# 2 variation, hold x_1 and y_1\n",
    "print('considering 2nd variation')\n",
    "x_train = np.vstack((x_2, x_3, x_4, x_5, x_6, x_7, x_8)) \n",
    "y_train = np.vstack((y_2, y_3, y_4, y_5, y_6, y_7, y_8)) \n",
    "w_train = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y_train\n",
    "y_hat = np.sign(x_1@w_train)\n",
    "# print(w_train)\n",
    "error_vec_2 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_1))]\n",
    "print('Errors: '+ str(sum(error_vec_2)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec_2)/16)+'%')\n",
    "\n",
    "# 3 variation, , hold x_2 and y_2\n",
    "print('considering 3rd variation')\n",
    "x_train = np.vstack((x_1, x_3, x_4, x_5, x_6, x_7, x_8)) \n",
    "y_train = np.vstack((y_1, y_3, y_4, y_5, y_6, y_7, y_8)) \n",
    "w_train = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y_train\n",
    "y_hat = np.sign(x_2@w_train)\n",
    "# print(w_train)\n",
    "error_vec_3 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_2))]\n",
    "print('Errors: '+ str(sum(error_vec_3)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec_3)/16)+'%')\n",
    "\n",
    "# 4 variation, hold x_3 and y_3\n",
    "print('considering 4th variation')\n",
    "x_train = np.vstack((x_1, x_2, x_4, x_5, x_6, x_7, x_8)) \n",
    "y_train = np.vstack((y_1, y_2, y_4, y_5, y_6, y_7, y_8)) \n",
    "w_train = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y_train\n",
    "y_hat = np.sign(x_3@w_train)\n",
    "# print(w_train)\n",
    "error_vec_4 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_3))]\n",
    "print('Errors: '+ str(sum(error_vec_4)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec_4)/16)+'%')\n",
    "\n",
    "# 5 variation, hold x_4 and y_4\n",
    "print('considering 5th variation')\n",
    "x_train = np.vstack((x_1, x_2, x_3, x_5, x_6, x_7, x_8)) \n",
    "y_train = np.vstack((y_1, y_2, y_3, y_5, y_6, y_7, y_8)) \n",
    "w_train = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y_train\n",
    "y_hat = np.sign(x_4@w_train)\n",
    "# print(w_train)\n",
    "error_vec_5 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_4))]\n",
    "print('Errors: '+ str(sum(error_vec_5)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec_5)/16)+'%')\n",
    "\n",
    "# 6 variation, hold x_5 and y_5\n",
    "print('considering 6th variation')\n",
    "x_train = np.vstack((x_1, x_2, x_3, x_4, x_6, x_7, x_8)) \n",
    "y_train = np.vstack((y_1, y_2, y_3, y_4, y_6, y_7, y_8)) \n",
    "w_train = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y_train\n",
    "y_hat = np.sign(x_5@w_train)\n",
    "# print(w_train)\n",
    "error_vec_6 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_5))]\n",
    "print('Errors: '+ str(sum(error_vec_6)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec_6)/16)+'%')\n",
    "\n",
    "# 7 variation, hold x_6 and y_6\n",
    "print('considering 7th variation')\n",
    "x_train = np.vstack((x_1, x_2, x_3, x_4, x_5, x_7, x_8)) \n",
    "y_train = np.vstack((y_1, y_2, y_3, y_4, y_5, y_7, y_8)) \n",
    "w_train = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y_train\n",
    "y_hat = np.sign(x_6@w_train)\n",
    "# print(w_train)\n",
    "error_vec_7 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_6))]\n",
    "print('Errors: '+ str(sum(error_vec_7)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec_7)/16)+'%')\n",
    "\n",
    "# 8 variation, hold x_7 and y_7\n",
    "print('considering 8th variation')\n",
    "x_train = np.vstack((x_1, x_2, x_3, x_4, x_5, x_6, x_8)) \n",
    "y_train = np.vstack((y_1, y_2, y_3, y_4, y_5, y_6, y_8)) \n",
    "w_train = np.linalg.inv(x_train.transpose()@x_train)@x_train.transpose()@y_train\n",
    "y_hat = np.sign(x_7@w_train)\n",
    "# print(w_train)\n",
    "error_vec_8 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_7))]\n",
    "print('Errors: '+ str(sum(error_vec_8)))\n",
    "print('Percent error: '+str(100.0*sum(error_vec_8)/16)+'%')\n",
    "\n",
    "print('Final performance estimate:') \n",
    "# average_error_rate=(error_vec_1+error_vec_2+error_vec_3+error_vec_4+error_vec_5+error_vec_6+error_vec_7+error_vec_8)/8\n",
    "hola = ((1/16)*(sum(error_vec_1)+sum(error_vec_2)+sum(error_vec_3)+sum(error_vec_4)+sum(error_vec_5)+sum(error_vec_6)+sum(error_vec_7)+sum(error_vec_8))/8)*100\n",
    "print(str(hola)+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
